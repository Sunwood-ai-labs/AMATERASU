<p align="center">
<img src="https://raw.githubusercontent.com/Sunwood-ai-labs/AMATERASU/refs/heads/main/docs/amaterasu_main.png" width="100%">
<h1 align="center">ğŸŒ„ AMATERASU v0.2.0 ğŸŒ„</h1>
</p>

<p align="center">
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU">
    <img alt="GitHub Repo" src="https://img.shields.io/badge/github-AMATERASU-blue?logo=github">
  </a>
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU/releases">
    <img alt="GitHub release" src="https://img.shields.io/github/v/release/Sunwood-ai-labs/AMATERASU?include_prereleases&style=flat-square">
  </a>
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU/blob/main/LICENSE">
    <img alt="License" src="https://img.shields.io/github/license/Sunwood-ai-labs/AMATERASU?color=green">
  </a>
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU/stargazers">
    <img alt="GitHub stars" src="https://img.shields.io/github/stars/Sunwood-ai-labs/AMATERASU?style=social">
  </a>
</p>

<h2 align="center">
  ï½ Automated Construction of an LLM Platform on AWS ï½
</h2>

>[!IMPORTANT]
>AMATERASU is the successor project to [MOA](https://github.com/Sunwood-ai-labs/MOA).  It has evolved to run each AI service on a separate EC2 instance using Docker Compose, enabling easier deployment with Terraform.

## ğŸš€ Project Overview

AMATERASU is an automation tool for building a Large Language Model (LLM) platform on AWS.  While inheriting functionality from MOA, it provides more flexible scaling and management by running each service on its own dedicated EC2 instance.

Key Features:
- Simple EC2 instance management using Terraform
- Independent EC2 instances and Docker Compose environments for each service
- Service-level scaling and operation
- Secure communication and access control

## âœ¨ Main Features

- None (at this time)


## ğŸ”§ Usage

Follow the installation instructions and usage guidelines provided in this README to set up AMATERASU.


## ğŸ“¦ Installation Instructions

1. Clone the repository:
```bash
git clone https://github.com/Sunwood-ai-labs/AMATERASU.git
cd AMATERASU
```

2. Set environment variables:
```bash
cp .env.example .env
# Edit the .env file and configure the necessary credentials
```

3. Initialize and run Terraform:
```bash
cd terraform
terraform init
terraform plan
terraform apply
```

## ğŸ†• Latest News

v0.2.0 features a revamped architecture, with each AI service now running in a separate EC2 instance using Docker Compose. This improves scalability and manageability of individual services.  The English README has also been updated, and images have been added to improve the appearance of the release notes.

With the architecture overhaul, the README now includes an architecture diagram (not included in this translation), system requirements, installation instructions, module structure, deployment methods, example operational commands, detailed directory structure for each module, examples of the Docker Compose configuration file (`docker-compose.yml`) and environment variable file (`.env`), scripts for SSH connection to each module, and Docker Compose service management (start, stop, log display). For enhanced security, each EC2 instance is protected by a dedicated security group, and inter-service communication is controlled within the internal VPC network.


## ğŸŒ Module Structure

Each module runs using Docker Compose on a separate EC2 instance:

### open-webui Module (EC2 Instance)
```
ğŸ“ open-webui/
â”œâ”€â”€ ğŸ“„ docker-compose.yml  # open-webui and ollama configuration
â”œâ”€â”€ ğŸ“„ .env               # Environment variable settings
â””â”€â”€ ğŸ“ config/            # Configuration files
```

Example configuration (docker-compose.yml):
```yaml
version: '3'
services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ./data:/root/.ollama

  open-webui:
    image: open-webui/open-webui
    ports:
      - "3000:3000"
    environment:
      - OLLAMA_URL=http://ollama:11434
```

### litellm Module (EC2 Instance)
```
ğŸ“ litellm/
â”œâ”€â”€ ğŸ“„ docker-compose.yml  # litellm service configuration
â”œâ”€â”€ ğŸ“„ .env               # API key and other environment variables
â””â”€â”€ ğŸ“ config/            # LLM configuration files
```

### langfuse Module (EC2 Instance)
```
ğŸ“ langfuse/
â”œâ”€â”€ ğŸ“„ docker-compose.yml  # langfuse and DB configuration
â”œâ”€â”€ ğŸ“„ .env               # Environment variable settings
â””â”€â”€ ğŸ“ data/              # PostgreSQL data
```

## ğŸ”¨ Deployment Command Examples

Deploying only specific modules:
```bash
# Deploy only the open-webui module
terraform apply -target=module.ec2_open_webui

# Deploy only the litellm module
terraform apply -target=module.ec2_litellm

# Deploy only the langfuse module
terraform apply -target=module.ec2_langfuse
```

## ğŸ’» Module Management Commands

Connecting to each EC2 instance:
```bash
# SSH connection script
./scripts/connect.sh open-webui
./scripts/connect.sh litellm
./scripts/connect.sh langfuse
```

Docker Compose operations:
```bash
# Run within each instance
cd /opt/amaterasu/[module-name]
docker-compose up -d      # Start service
docker-compose down      # Stop service
docker-compose logs -f   # Display logs
```

## ğŸ”’ Security Configuration

- Each EC2 instance is protected by a dedicated security group.
- Inter-service communication is controlled within the internal VPC network.
- Only the minimum necessary ports are exposed.
- Permission management using IAM roles.

## ğŸ“š Directory Structure

```plaintext
amaterasu/
â”œâ”€â”€ terraform/          # Terraform code
â”‚   â”œâ”€â”€ modules/        # Modules for each EC2 instance
â”‚   â”œâ”€â”€ main.tf        # Main configuration
â”‚   â””â”€â”€ variables.tf   # Variable definitions
â”œâ”€â”€ modules/           # Docker Compose configuration for each service
â”‚   â”œâ”€â”€ open-webui/    # open-webui related files
â”‚   â”œâ”€â”€ litellm/      # litellm related files
â”‚   â””â”€â”€ langfuse/     # langfuse related files
â”œâ”€â”€ scripts/          # Operational scripts
â””â”€â”€ docs/            # Documentation
```

## âš ï¸ Important Changes

- Due to the revamped architecture, upgrading from previous versions requires manual migration following the provided steps.  Refer to the upgrade instructions for details.


## ğŸ“¦ Upgrade Instructions

1. Stop the existing environment.
2. Build the environment with the new architecture following the instructions in this README.
3. If data migration is necessary, perform the appropriate steps. (Specific steps are not provided.)


## ğŸ“„ License

This project is licensed under the MIT License.  See the [LICENSE](LICENSE) file for details.

## ğŸ‘ Acknowledgements

Thanks to iris-s-coon and Maki.

## ğŸ¤ Contributions

Contributions are welcome!  Here's how to get involved:

1. Fork this repository
2. Create a new branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push the branch (`git push origin feature/amazing-feature`)
5. Create a pull request

## ğŸ“§ Support

For questions or feedback, please feel free to contact us:
- Create an issue: [GitHub Issues](https://github.com/Sunwood-ai-labs/AMATERASU/issues)
- Email: support@sunwoodai.com

Build a more flexible and powerful AI infrastructure with AMATERASU! âœ¨