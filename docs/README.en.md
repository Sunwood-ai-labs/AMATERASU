<p align="center">
<img src="https://raw.githubusercontent.com/Sunwood-ai-labs/AMATERASU/refs/heads/main/docs/amaterasu_main.png" width="100%">
<h1 align="center">ğŸŒ„ AMATERASU v0.2.0 ğŸŒ„</h1>
</p>

<p align="center">
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU">
    <img alt="GitHub Repo" src="https://img.shields.io/badge/github-AMATERASU-blue?logo=github">
  </a>
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU/releases">
    <img alt="GitHub release" src="https://img.shields.io/github/v/release/Sunwood-ai-labs/AMATERASU?include_prereleases&style=flat-square">
  </a>
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU/blob/main/LICENSE">
    <img alt="License" src="https://img.shields.io/github/license/Sunwood-ai-labs/AMATERASU?color=green">
  </a>
  <a href="https://github.com/Sunwood-ai-labs/AMATERASU/stargazers">
    <img alt="GitHub stars" src="https://img.shields.io/github/stars/Sunwood-ai-labs/AMATERASU?style=social">
  </a>
</p>

<h2 align="center">
  ï½ Automated Construction of an LLM Platform on AWS ï½
</h2>

>[!IMPORTANT]
>This repository utilizes [SourceSage](https://github.com/Sunwood-ai-labs/SourceSage).  Approximately 90% of the release notes, README, and commit messages were generated using [SourceSage](https://github.com/Sunwood-ai-labs/SourceSage) and [claude.ai](https://claude.ai/).

>[!NOTE]
>AMATERASU is the successor project to [MOA](https://github.com/Sunwood-ai-labs/MOA). It has evolved to run each AI service on an independent EC2 instance using Docker Compose, enabling easier deployment with Terraform.


## ğŸš€ Project Overview

AMATERASU is an automation tool for building an LLM (Large Language Model) platform on AWS.  While inheriting the functionality of MOA, it offers more flexible scaling and management by running each service on a separate EC2 instance.

Key Features:
- Simple EC2 instance management using Terraform
- Independent EC2 instances and Docker Compose environments for each service
- Service-level scaling and operation
- Secure communication and access control

## âœ¨ Main Features

- None (at this time)


## ğŸ”§ Usage

Follow the installation instructions and usage guide in this README to set up AMATERASU.


## ğŸ“¦ Installation

1. Clone the repository:
```bash
git clone https://github.com/Sunwood-ai-labs/AMATERASU.git
cd AMATERASU
```

2. Set environment variables:
```bash
cp .env.example .env
# Edit the .env file and set the necessary credentials
```

3. Initialize and run Terraform:
```bash
cd terraform
terraform init
terraform plan
terraform apply
```


## SSH

```bash
ssh -i "C:\Users\makim\.ssh\AMATERASU-terraform-keypair-tokyo-PEM.pem" ubuntu@i-062f3dd7388a5da8a
```

## ğŸ†• What's New

v0.2.0 features a revamped architecture, running each AI service in a separate EC2 instance using Docker Compose. This improves scalability and manageability for each service.  The English README has been updated, and images have been added to improve the appearance of the release notes.

The architecture refresh has added an architecture diagram, system requirements, installation instructions, module structure, deployment methods, operational command examples, detailed directory structures for each module, examples of Docker Compose configuration files (`docker-compose.yml`) and environment variable files (`.env`), SSH connection to each module, and scripts for managing services (start, stop, log display) using Docker Compose. For enhanced security, each EC2 instance is protected by a separate security group, and inter-service communication is controlled within the internal VPC network.


## ğŸŒ Module Structure

Each module runs using Docker Compose on a separate EC2 instance:

### open-webui Module (EC2 Instance)
```
ğŸ“ open-webui/
â”œâ”€â”€ ğŸ“„ docker-compose.yml  # open-webui and ollama configuration
â”œâ”€â”€ ğŸ“„ .env               # Environment variable settings
â””â”€â”€ ğŸ“ config/            # Configuration files
```

Example Configuration (docker-compose.yml):
```yaml
version: '3'
services:
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
    volumes:
      - ./data:/root/.ollama

  open-webui:
    image: open-webui/open-webui
    ports:
      - "3000:3000"
    environment:
      - OLLAMA_URL=http://ollama:11434
```

### litellm Module (EC2 Instance)
```
ğŸ“ litellm/
â”œâ”€â”€ ğŸ“„ docker-compose.yml  # litellm service configuration
â”œâ”€â”€ ğŸ“„ .env               # API key and other environment variables
â””â”€â”€ ğŸ“ config/            # LLM configuration files
```

### langfuse Module (EC2 Instance)
```
ğŸ“ langfuse/
â”œâ”€â”€ ğŸ“„ docker-compose.yml  # langfuse and DB configuration
â”œâ”€â”€ ğŸ“„ .env               # Environment variable settings
â””â”€â”€ ğŸ“ data/              # PostgreSQL data
```

## ğŸ”¨ Deployment Command Examples

Deploying specific modules only:
```bash
# Deploy only the open-webui module
terraform apply -target=module.ec2_open_webui

# Deploy only the litellm module
terraform apply -target=module.ec2_litellm

# Deploy only the langfuse module
terraform apply -target=module.ec2_langfuse
```

## ğŸ’» Module Management Commands

Connecting to each EC2 instance:
```bash
# SSH connection script
./scripts/connect.sh open-webui
./scripts/connect.sh litellm
./scripts/connect.sh langfuse
```

Docker Compose operations:
```bash
# Run within each instance
cd /opt/amaterasu/[module-name]
docker-compose up -d      # Start services
docker-compose down      # Stop services
docker-compose logs -f   # View logs
```

## ğŸ”’ Security Configuration

- Each EC2 instance is protected by a separate security group
- Inter-service communication is controlled within the internal VPC network
- Only the minimum necessary ports are exposed
- Permission management using IAM roles

## ğŸ“š Directory Structure

```plaintext
amaterasu/
â”œâ”€â”€ terraform/          # Terraform code
â”‚   â”œâ”€â”€ modules/        # Modules for each EC2 instance
â”‚   â”œâ”€â”€ main.tf        # Main configuration
â”‚   â””â”€â”€ variables.tf   # Variable definitions
â”œâ”€â”€ modules/           # Docker Compose configuration for each service
â”‚   â”œâ”€â”€ open-webui/    # open-webui related files
â”‚   â”œâ”€â”€ litellm/      # litellm related files
â”‚   â””â”€â”€ langfuse/     # langfuse related files
â”œâ”€â”€ scripts/          # Operational scripts
â””â”€â”€ docs/            # Documentation
```

## âš ï¸ Important Changes

- Due to the architecture refresh, upgrading from previous versions requires manual migration following the provided steps. Refer to the upgrade instructions for details.


## ğŸ“¦ Upgrade Instructions

1. Stop the existing environment.
2. Build the environment with the new architecture following the instructions in this README.
3. If data migration is necessary, perform the appropriate steps. (Specific steps are not provided.)


## ğŸ“„ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

## ğŸ‘ Acknowledgements

Thanks to iris-s-coon and Maki.

## ğŸ¤ Contributing

Contributions are welcome!  Here's how to get involved:

1. Fork this repository
2. Create a new branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push the branch (`git push origin feature/amazing-feature`)
5. Create a pull request

## ğŸ“§ Support

For questions or feedback, please feel free to contact us:
- Create an issue: [GitHub Issues](https://github.com/Sunwood-ai-labs/AMATERASU/issues)
- Email: support@sunwoodai.com

Build a more flexible and powerful AI infrastructure with AMATERASU! âœ¨